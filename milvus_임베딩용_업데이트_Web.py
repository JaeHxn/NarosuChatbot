from fastapi import FastAPI, File, UploadFile, BackgroundTasks
from fastapi.responses import HTMLResponse, RedirectResponse
from io import BytesIO
import pandas as pd
import numpy as np
import re
import os
import time
import tiktoken        

from openai import OpenAI
from pymilvus import (
    connections, utility,
    FieldSchema, CollectionSchema,
    DataType, Collection
)

app = FastAPI()

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY     = os.getenv('OPENAI_API_KEY')
MODEL       = "text-embedding-3-small"
MILVUS_HOST = '114.110.135.96'
# CHUNK_SIZE  = 2000
MILVUS_PORT = '19530'
COLLECTION  = "ownerclan_weekly_0428"

MAX_TOKENS  = 200_000
QUERY_BATCH = 1000  # í•œ ë²ˆì— ì¡°íšŒí•  ìƒí’ˆì½”ë“œ ê°œìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) OpenAI í´ë¼ì´ì–¸íŠ¸ & Milvus ì—°ê²°
client = OpenAI(api_key=API_KEY)
connections.connect(alias='default', host=MILVUS_HOST, port=MILVUS_PORT)

# ì‚¬ì „ max_length ê³„ì‚°
excel_paths = glob("db/ownerclan_narosu_ì˜¤ë„ˆí´ëœ50ë§Œ_*.xlsx")

# í•œê¸€â†’ì˜ë¬¸ í•„ë“œëª… ë§¤í•‘
column_map = {
    "ìƒí’ˆì½”ë“œ":        "product_code",
    "ì¹´í…Œê³ ë¦¬ì½”ë“œ":    "category_code",
    "ì¹´í…Œê³ ë¦¬ëª…":      "category_name",
    "ë§ˆì¼“ìƒí’ˆëª…":      "market_product_name",
    "ë§ˆì¼“ì‹¤ì œíŒë§¤ê°€":  "market_price",
    "ë°°ì†¡ë¹„":          "shipping_fee",
    "ë°°ì†¡ìœ í˜•":        "shipping_type",
    "ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰":    "max_quantity",
    "ì¡°í•©í˜•ì˜µì…˜":      "composite_options",
    "ì´ë¯¸ì§€ì¤‘":        "image_url",
    "ì œì‘/ìˆ˜ì…ì‚¬":     "manufacturer",
    "ëª¨ë¸ëª…":          "model_name",
    "ì›ì‚°ì§€":          "origin",
    "í‚¤ì›Œë“œ":          "keywords",
    "ë³¸ë¬¸ìƒì„¸ì„¤ëª…":    "description",
    "ë°˜í’ˆë°°ì†¡ë¹„":      "return_shipping_fee",
    "ë…ë¦½í˜•":          "independent_option",
    "ì¡°í•©í˜•":          "composite_flag"
}
numeric_fields = {"market_price", "shipping_fee", "max_quantity", "return_shipping_fee"}

# ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
def make_text(row):
    return " || ".join([
        f"cat:{row['ì¹´í…Œê³ ë¦¬ëª…']}",
        f"name:{row['ë§ˆì¼“ìƒí’ˆëª…']}",
        f"opts:{row['ì¡°í•©í˜•ì˜µì…˜']}"
    ])

# í† í° ê¸°ì¤€ ë°°ì¹˜ ë¶„í• 
def split_batches(texts, max_tokens=MAX_TOKENS):
    enc = tiktoken.get_encoding("cl100k_base")
    batches, batch, tokens = [], [], 0

    for t in texts:
        tk = len(enc.encode(str(t)))
        # ë‹¨ì¼ í…ìŠ¤íŠ¸ê°€ í•œë„ ì´ˆê³¼í•˜ë©´, ê¸°ì¡´ ë°°ì¹˜ ë‹«ê³  ë‹¨ë… ë°°ì¹˜ë¡œ
        if tk > max_tokens:
            if batch:
                batches.append(batch)
            batches.append([t])
            batch, tokens = [], 0
            continue

        # ê¸°ì¡´ ë°°ì¹˜ì— ë„£ìœ¼ë©´ ì´ˆê³¼ë  ë•Œ, ë°°ì¹˜ ë‹«ê³  ìƒˆë¡œ ì‹œì‘
        if tokens + tk > max_tokens:
            batches.append(batch)
            batch, tokens = [], 0

        batch.append(t)
        tokens += tk

    if batch:
        batches.append(batch)
    return batches


# â€œmax_tokens_per_requestâ€ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°˜ìœ¼ë¡œ ìª¼ê°œ ì¬ì‹œë„
def try_batch(batch: list[str]) -> list[list[float]]:
    try:
        resp = client.embeddings.create(input=batch, model=MODEL)
        return [d.embedding for d in resp.data]
    except Exception as e:
        msg = getattr(e, "args", [None])[0]
        if "max_tokens_per_request" in str(msg) and len(batch) > 1:
            mid = len(batch) // 2
            return try_batch(batch[:mid]) + try_batch(batch[mid:])
        else:
            # ë‹¨ì¼ í•­ëª©ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ê±´ë„ˆëœ€
            return []
            


# 5) ì»¬ë ‰ì…˜ ë¡œë“œ or ìƒì„±
if not utility.has_collection(COLLECTION):
    fields = [
        FieldSchema("product_code", DataType.VARCHAR, is_primary=True, max_length=200, auto_id=False),
        FieldSchema("emb",  DataType.FLOAT_VECTOR, dim=1536),
        FieldSchema("text", DataType.VARCHAR,      max_length=65535),
        FieldSchema("category_code",       DataType.VARCHAR,      max_length=20),
        FieldSchema("category_name",       DataType.VARCHAR,      max_length=256),
        FieldSchema("market_product_name", DataType.VARCHAR,      max_length=512),
        FieldSchema("market_price",        DataType.INT64),
        FieldSchema("shipping_fee",        DataType.INT64),
        FieldSchema("shipping_type",       DataType.VARCHAR,      max_length=16),
        FieldSchema("max_quantity",        DataType.INT64),
        FieldSchema("composite_options",   DataType.VARCHAR,      max_length=65535),
        FieldSchema("image_url",           DataType.VARCHAR,      max_length=2048),
        FieldSchema("manufacturer",        DataType.VARCHAR,      max_length=128),
        FieldSchema("model_name",          DataType.VARCHAR,      max_length=256),
        FieldSchema("origin",              DataType.VARCHAR,      max_length=100),
        FieldSchema("keywords",            DataType.VARCHAR,      max_length=1024),
        FieldSchema("description",         DataType.VARCHAR,      max_length=65535),
        FieldSchema("return_shipping_fee", DataType.INT64),
        FieldSchema("independent_option",  DataType.VARCHAR,      max_length=8192),   # í…ìŠ¤íŠ¸ë¡œ
        FieldSchema("composite_flag",      DataType.VARCHAR,      max_length=16384),   # í…ìŠ¤íŠ¸ë¡œ
        FieldSchema("embedding_date",      DataType.INT64)  # â† ì—¬ê¸°ì— ì¶”ê°€
    ]

    schema     = CollectionSchema(fields, description="Weekly Top 50k Products")
    collection = Collection(name=COLLECTION, schema=schema)
    collection.create_index(
        field_name="emb",
        index_params={"index_type":"IVF_FLAT","metric_type":"L2","params":{"nlist":128}}
    )
else:
    collection = Collection(name=COLLECTION)
collection.load()

# 6) ì—‘ì…€ íŒŒì¼ë³„ Upsert ë£¨í”„
start_all = time.time()
for path in tqdm(excel_paths, desc="ğŸ“Š ì—‘ì…€ ì²˜ë¦¬ ì§„í–‰ë¥ ", unit="íŒŒì¼"):
    t0 = time.time()
    df = pd.read_excel(path, header=1)

    # (1) ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ë¯¸ë¦¬ ê³„ì‚°
    df["__text"] = df.apply(make_text, axis=1)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # (2) Milvusì— ë¡œë“œ & ê¸°ì¡´ ì €ì¥ëœ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    collection.load()
    codes_all = df["ìƒí’ˆì½”ë“œ"].astype(str).tolist()
    expr = "product_code in [" + ",".join(f'"{c}"' for c in codes_all) + "]"

    # ì—¬ê¸°ì— ìš°ë¦¬ê°€ ë¹„êµí•  ëª¨ë“  í•„ë“œë¥¼ ë‚˜ì—´
    compare_fields = ["product_code", "text"] + list(numeric_fields) + [
    "shipping_type", "max_quantity", "composite_options",
    "independent_option", "composite_flag",
    "category_code", "category_name", "market_product_name", "image_url",
    "manufacturer", "model_name", "origin", "keywords", "description"
]

    # existing_rows = collection.query(expr, output_fields=compare_fields)
    
    existing_meta = {}
    for i in range(0, len(codes_all), QUERY_BATCH):
        batch_codes = codes_all[i : i + QUERY_BATCH]
        expr = "product_code in [" + ",".join(f'"{c}"' for c in batch_codes) + "]"
        rows = collection.query(expr, output_fields=compare_fields)
        for r in rows:
            existing_meta[r["product_code"]] = { f: r[f] for f in compare_fields }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹ ê·œì´ê±°ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ë°”ë€ í–‰ë§Œ ë‚¨ê¸°ê¸°
    def has_changed(row):
        code = str(row["ìƒí’ˆì½”ë“œ"])
        old = existing_meta.get(code)
        # â‘  ì™„ì „ ì‹ ê·œ
        if old is None:
            return True
        # â‘¡ í…ìŠ¤íŠ¸ê°€ ë³€ê²½ëì„ ë•Œ
        if old["text"] != row["__text"]:
            return True
        # â‘¢ ê° ë©”íƒ€í•„ë“œê°€ ë³€ê²½ëì„ ë•Œ
        for kor, eng in column_map.items():
            if eng == "product_code":
                continue
            if eng in numeric_fields:
                if int(old.get(eng, -1)) != int(row[kor]):
                    return True
            else:
                if str(old.get(eng, "")) != str(row[kor]):
                    return True
        # ëª¨ë‘ ê°™ìœ¼ë©´ ë³€ê²½ ì—†ìŒ
        return False

    mask    = df.apply(has_changed, axis=1)
    proc_df = df[mask]
    to_keep = df[~mask]
    
    print(f"ğŸ™…â€â™€ï¸ ê±´ë„ˆë›´ í–‰ ìˆ˜: {len(df) - len(proc_df)}ê°œ")  # ì—¬ê¸°ì—!


    if proc_df.empty:
        print(f"âš¡ {os.path.basename(path)}: ë³€ê²½ëœ í•­ëª© ì—†ìŒ, ì—…ì„œíŠ¸ ìƒëµ")
        continue

    #ë³€ê²½ëœ í–‰ë§Œ ì„ë² ë”© ìƒì„±
    texts = proc_df["__text"].astype(str).tolist()
    batches = split_batches(texts, max_tokens=MAX_TOKENS)
    embeddings = []
    for idx, batch in enumerate(batches, 1):
        clean = [t for t in batch if t.strip() and t.lower() not in ("nan","none")]
        embs  = try_batch(clean)
        embeddings.extend(embs)
        print(f"âœ… ë°°ì¹˜ {idx}/{len(batches)} ì„ë² ë”© ì™„ë£Œ (ë¬¸ì¥ìˆ˜={len(clean)})")
    embeddings = np.array(embeddings)

    # 2) Milvus upsert (2,000ê°œì”©)
    total = len(embeddings)
    date_int = int(date.today().strftime("%Y%m%d"))
    codes = proc_df["ìƒí’ˆì½”ë“œ"].astype(str).tolist()[:total]
    txts  = proc_df["__text"].tolist()[:total]
    metas = [
        (proc_df[k].astype(int).tolist() if eng in numeric_fields else proc_df[k].astype(str).tolist())[:total]
        for k, eng in list(column_map.items())[1:]
    ]
    dates = [date_int] * total

    CHUNK = 2000
    for s in range(0, total, CHUNK):
        e = min(s + CHUNK, total)
        entities = [
            codes[s:e],
            embeddings[s:e].tolist(),
            txts[s:e],
            *[m[s:e] for m in metas],
            dates[s:e]
        ]
        collection.upsert(entities)
        collection.flush()
        print(f"âœ… Milvus ì—…ì„œíŠ¸ ì™„ë£Œ {s}â€“{e}/{total}")

    # 3) 30ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ
    threshold = int((date.today() - timedelta(days=30)).strftime("%Y%m%d"))
    collection.delete(f"embedding_date < {threshold}")
    collection.flush()

    print(f"âœ… {os.path.basename(path)} ì™„ë£Œ ({time.time()-t0:.1f}s)")
    print(f"âœ… Milvus ì‚½ì… ì™„ë£Œ ({total}ê°œ, {embeddings.shape})")

    print(len(df))       # ì „ì²´ í–‰ ìˆ˜
    print(len(proc_df))  # ë³€ê²½ëœ í–‰ ìˆ˜
    print(len(embeddings))  # ìƒì„±ëœ ì„ë² ë”© ìˆ˜


print(f"\n ì „ì²´ ì™„ë£Œ: {time.time()-start_all:.1f}s")

# ê²€ìƒ‰ í•¨ìˆ˜
def semantic_search_with_price(query, top_k=5):
    collection.load()
    m = re.search(r'(\d+)\s*ì›', query)
    price = int(m.group(1)) if m else None
    q_emb = client.embeddings.create(input=[query], model=MODEL).data[0].embedding
    expr = f"market_price <= {price}" if price else None
    results = collection.search(
        data=[q_emb], anns_field="emb",
        param={"metric_type":"L2","params":{"nprobe":30}},
        limit=top_k, expr=expr,
        output_fields=list(column_map.values())+['text']
    )
    for hit in results[0]:
        print(f" â€¢ {hit.entity.get('market_product_name')} â€” {hit.entity.get('market_price')}ì›")

# ì˜ˆì‹œ
if __name__ == "__main__":
    print("ìº í•‘ìš©í’ˆ ì¶”ì²œí•´ì¤˜")
    semantic_search_with_price("ìº í•‘ìš©í’ˆ ì¶”ì²œí•´ì¤˜", 5)
    print("==========================")

    print("ì—¬ë¦„ í‹°ì…”ì¸  ì¤‘ 3000ì› ì´í•˜")
    semantic_search_with_price("ì—¬ë¦„ í‹°ì…”ì¸  ì¤‘ 3000ì› ì´í•˜", 5)
    print("==========================")

    print("í° ê°€ë°© ì¶”ì²œí•´ì¤˜ì¤˜")
    semantic_search_with_price("í° ê°€ë°© ì¶”ì²œí•´ì¤˜ì¤˜", 5)
    print("==========================")

    print("ì—¬ë¦„ìš© ì–‡ì€ ê°•ì•„ì§€ ì˜· ì¶”ì²œë°›ê³  ì‹¶ì–´ìš”")
    semantic_search_with_price("ì—¬ë¦„ìš© ì–‡ì€ ê°•ì•„ì§€ ì˜· ì¶”ì²œë°›ê³  ì‹¶ì–´ìš”", 5)
    print("==========================")

    print("ê²¨ìš¸ìš©í’ˆ ì¶”ì²œí•´ì¤˜")
    semantic_search_with_price("ê²¨ìš¸ìš©í’ˆ ì¶”ì²œí•´ì¤˜", 5)
    print("==========================")

    print("ì¬í¬ë¦¼ ì¶”ì²œí•´ì¤˜")
    semantic_search_with_price("ì„ í¬ë¦¼ ì¶”ì²œí•´ì¤˜", 5)
    print("==========================")

    print("ì‹œì›í•œ ì—¬ë¦„ìš©í’ˆ ì¶”ì²œí•´ì¤˜")
    semantic_search_with_price("ì‹œì›í•œ ì—¬ë¦„ìš©í’ˆ ì¶”ì²œí•´ì¤˜", 5)
    print("==========================")


# # â”€â”€ ì›¹ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# @app.get("/", response_class=HTMLResponse)
# async def home():
#     return """
#     <html>
#       <head><title>ì—‘ì…€ ì—…ë¡œë“œ</title></head>
#       <body>
#         <h2>ì—¬ëŸ¬ ê°œì˜ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ</h2>
#         <form action="/upload" enctype="multipart/form-data" method="post">
#           <input name="files" type="file" multiple><br/><br/>
#           <button type="submit">ì—…ë¡œë“œ ë° ì²˜ë¦¬</button>
#         </form>
#       </body>
#     </html>
#     """

# @app.post("/upload", response_class=HTMLResponse)
# async def upload(files: list[UploadFile] = File(...)):
#     total = 0
#     for file in files:
#         content = await file.read()
#         df = pd.read_excel(BytesIO(content), header=1)
#         cnt = process_df(df)
#         total += cnt
#     return f"<h3>ì²˜ë¦¬ ì™„ë£Œ: ì´ {total}ê±´ ì—…ì„œíŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ‰</h3><a href='/'>ëŒì•„ê°€ê¸°</a>"